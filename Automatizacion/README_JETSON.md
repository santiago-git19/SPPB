# TensorRT Pose Estimation - Jetson Nano Optimizado

## Descripci√≥n

Sistema completo de estimaci√≥n de poses para Jetson Nano, optimizado para:
- **Monitoreo autom√°tico de recursos** (CPU, RAM, GPU, temperatura)
- **Manejo autom√°tico de swap** para evitar crashes por memoria
- **Limitaci√≥n inteligente de CPU** para mantener temperatura controlada
- **Reportes de progreso detallados** con estad√≠sticas en tiempo real
- **Gesti√≥n robusta de errores** por falta de memoria

## Archivos del Sistema

### Scripts Principales
- `example_trt_pose_final.py` - Script principal optimizado
- `convert_model_to_tensorrt.py` - Convertidor PyTorch ‚Üí TensorRT con monitoreo completo
- `model_manager.py` - Gestor de modelos con verificaci√≥n y conversi√≥n autom√°tica
- `download_models_v2.py` - Descargador autom√°tico de dependencias
- `utils/jetson_utils.py` - Utilidades espec√≠ficas para Jetson Nano
- `utils/trt_pose_proc.py` - Procesador TensorRT Pose

### Archivos de Configuraci√≥n
- `trt_pose_config.json` - Configuraci√≥n autom√°tica generada
- `models/` - Directorio para modelos pre-entrenados
- `configs/` - Directorio para archivos de configuraci√≥n

## Conversi√≥n de Modelos PyTorch ‚Üí TensorRT

### üîÑ Conversi√≥n Autom√°tica (Recomendado)
```bash
# Conversi√≥n autom√°tica con monitoreo completo
python convert_model_to_tensorrt.py
```

Este proceso:
- ‚úÖ **Configura swap de 4GB** autom√°ticamente
- ‚úÖ **Limita CPU a 1 core** para evitar sobrecalentamiento
- ‚úÖ **Monitorea recursos** cada 15 segundos durante conversi√≥n
- ‚úÖ **Reporta progreso** con temperatura y memoria
- ‚úÖ **Pausas autom√°ticas** si temperatura > 70¬∞C o memoria > 80%
- ‚úÖ **Verifica modelo convertido** con benchmark de rendimiento
- ‚úÖ **Tiempo estimado**: 5-15 minutos en Jetson Nano

### üìä Gesti√≥n de Modelos
```bash
# Verificar estado de modelos
python model_manager.py --check

# Conversi√≥n solo si es necesario
python model_manager.py --auto

# Validar modelo TensorRT existente
python model_manager.py --validate

# Reporte completo del sistema
python model_manager.py --status
```

### ‚öôÔ∏è Configuraci√≥n Manual de Swap (si falla autom√°tico)
```bash
# Crear swap de 4GB para conversi√≥n
sudo fallocate -l 4G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile

# Verificar swap activo
swapon --show
free -h
```

### üìà Monitoreo Durante Conversi√≥n
El script muestra logs como:
```
2025-01-XX 10:15:30 - INFO - ‚ö° Iniciando conversi√≥n PyTorch ‚Üí TensorRT...
2025-01-XX 10:15:45 - INFO - ‚úÖ Modelo PyTorch: 45.2 MB
2025-01-XX 10:16:00 - INFO - üîÑ Ejecutando torch2trt...
2025-01-XX 10:16:00 - INFO -    Esto puede tomar 5-15 minutos en Jetson Nano...
2025-01-XX 10:16:30 - INFO - ‚è±Ô∏è Conversi√≥n en progreso (0.5 min) - Memoria: 72.3% - Temp: 58.2¬∞C
2025-01-XX 10:17:00 - INFO - ‚è±Ô∏è Conversi√≥n en progreso (1.0 min) - Memoria: 75.1% - Temp: 61.4¬∞C
2025-01-XX 10:18:00 - WARNING - üå°Ô∏è ALERTA TEMPERATURA: 71.2¬∞C - Pausando para enfriar...
2025-01-XX 10:20:45 - INFO - ‚úÖ Conversi√≥n completada en 4.8 minutos
2025-01-XX 10:20:50 - INFO - ‚úÖ Modelo TensorRT guardado: resnet18_baseline_att_224x224_A_epoch_249_trt.pth (38.7 MB)
2025-01-XX 10:21:00 - INFO - üìä Resultados de rendimiento:
2025-01-XX 10:21:00 - INFO -    PyTorch: 145.2 ms por inferencia
2025-01-XX 10:21:00 - INFO -    TensorRT: 32.7 ms por inferencia
2025-01-XX 10:21:00 - INFO -    Aceleraci√≥n: 4.4x
```

## Instalaci√≥n Autom√°tica

### 1. Descargar Dependencias
```bash
# Ejecutar descargador autom√°tico
python download_models_v2.py
```

Este script autom√°ticamente:
- ‚úÖ Verifica requisitos del sistema
- ‚úÖ Instala dependencias de Python
- ‚úÖ Descarga modelos pre-entrenados
- ‚úÖ Configura directorios necesarios
- ‚úÖ Crea archivo de configuraci√≥n

### 2. Instalaci√≥n Manual de TensorRT Pose (si es necesario)
```bash
# Clonar repositorio TensorRT Pose
git clone https://github.com/NVIDIA-AI-IOT/trt_pose
cd trt_pose
sudo python setup.py install

# Clonar torch2trt
git clone https://github.com/NVIDIA-AI-IOT/torch2trt
cd torch2trt
sudo python setup.py install
```

## Uso del Sistema

### üöÄ Flujo Completo Recomendado
```bash
# 1. Descargar dependencias
python download_models_v2.py

# 2. Convertir modelo a TensorRT (primera vez)
python convert_model_to_tensorrt.py

# 3. Procesar video con modelo optimizado
python example_trt_pose_final.py
```

### ‚ö° Conversi√≥n R√°pida
```bash
# Conversi√≥n autom√°tica solo si es necesario
python model_manager.py --auto
python example_trt_pose_final.py
```

### üîß Uso Avanzado
```bash
# Ejecutar procesamiento con monitoreo autom√°tico
python example_trt_pose_final.py
```

### Configuraci√≥n de Swap (autom√°tico)
El sistema autom√°ticamente:
- Detecta si hay swap activo
- Crea y activa 2GB de swap si es necesario
- Configura permisos apropiados

### Monitoreo Manual de Recursos
```bash
# Monitorear recursos por 5 minutos
python utils/jetson_utils.py 5
```

### Configuraci√≥n Personalizada
Editar `trt_pose_config.json`:
```json
{
  "model_paths": {
    "topology": "configs/human_pose.json",
    "pytorch_model": "models/resnet18_baseline_att_224x224_A_epoch_249.pth",
    "tensorrt_model": "models/resnet18_baseline_att_224x224_A_epoch_249_trt.pth"
  },
  "jetson_config": {
    "enable_swap": true,
    "swap_size_gb": 2,
    "max_cpu_cores": 2,
    "memory_limit_percent": 85,
    "temperature_limit": 75
  }
}
```

## Caracter√≠sticas del Sistema

### üîç Monitoreo de Recursos
- **CPU**: Uso porcentual y frecuencia
- **Memoria**: RAM y swap con alertas autom√°ticas
- **Temperatura**: Monitoreo continuo con alertas
- **GPU**: Estad√≠sticas usando `tegrastats`
- **Red**: Estad√≠sticas de tr√°fico

### üö® Sistema de Alertas
- **Memoria > 85%**: Libera autom√°ticamente recursos
- **Temperatura > 75¬∞C**: Reduce carga de procesamiento
- **CPU > 90%**: Optimiza uso de cores

### ‚öôÔ∏è Optimizaciones Autom√°ticas
- **Variables de entorno**: Configuraci√≥n CUDA optimizada
- **Afinidad de CPU**: Limita a 2 cores para control t√©rmico
- **Cache CUDA**: Deshabilitado para ahorrar memoria
- **Garbage Collection**: Autom√°tico bajo presi√≥n de memoria

### üìä Reportes Detallados
```
=== RECURSOS JETSON (t=145.3s) ===
CPU: 67.2%
RAM: 78.5% (3.1GB/4.0GB)
SWAP: 15.2% (0.3GB/2.0GB)
Temperatura: 52.3¬∞C

üéØ Progreso: 1250/3000 (41.7%) - FPS: 8.6 - ETA: 203.4s
```

## Flujo de Procesamiento

### 1. Inicializaci√≥n
- ‚úÖ Configurar swap autom√°tico
- ‚úÖ Limitar cores de CPU
- ‚úÖ Iniciar monitoreo de recursos
- ‚úÖ Cargar modelo TensorRT optimizado

### 2. Procesamiento de Video
- üé¨ Abrir video de entrada
- üîÑ Procesar frame por frame con keypoints
- üé® Dibujar esqueleto en tiempo real
- üíæ Guardar video procesado
- üìà Reportar progreso cada 10 segundos

### 3. Manejo de Recursos
- üö® Detectar presi√≥n de memoria
- üßπ Liberar recursos autom√°ticamente
- üå°Ô∏è Monitorear temperatura
- ‚è∏Ô∏è Pausas autom√°ticas para enfriamiento

### 4. Finalizaci√≥n
- üìä Estad√≠sticas completas
- üßπ Limpieza de recursos
- üîÑ Restaurar configuraci√≥n CPU

## Comandos de Monitoreo Manual

### Verificar Estado del Sistema
```bash
# Temperatura
cat /sys/devices/virtual/thermal/thermal_zone0/temp

# Memoria
free -h

# Swap
swapon --show

# GPU (si tegrastats est√° disponible)
tegrastats --interval 1000
```

### Configurar Swap Manualmente
```bash
# Crear swap de 2GB
sudo fallocate -l 2G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile

# Verificar
swapon --show
```

### Limitar CPU Manualmente
```bash
# Limitar proceso a cores 0 y 1
taskset -cp 0,1 [PID]

# Verificar afinidad
taskset -p [PID]
```

## Soluci√≥n de Problemas

### Error: "Out of Memory"
```bash
# Verificar memoria disponible
free -h

# Activar swap si no est√° activo
sudo swapon /swapfile

# Reducir resoluci√≥n de video o procesar menos frames
```

### Error: "Model not found"
```bash
# Ejecutar descargador autom√°tico
python download_models_v2.py

# Verificar rutas en configuraci√≥n
cat trt_pose_config.json
```

### Temperatura alta (>80¬∞C)
```bash
# El sistema autom√°ticamente:
# - Pausa procesamiento
# - Reduce cores de CPU
# - Limpia memoria

# Verificar ventilaci√≥n del Jetson Nano
```

### Rendimiento bajo
```bash
# Verificar uso de TensorRT
# Ver logs del script para confirmar modelo optimizado

# Reducir resoluci√≥n de entrada
# Procesar menos frames por segundo
```

## Logs y Depuraci√≥n

### Habilitar Logs Detallados
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### Archivos de Log
- Salida est√°ndar: Progreso y estad√≠sticas
- Alertas: Eventos de recursos y temperaturas
- Errores: Problemas de procesamiento

### Ejemplo de Log Completo
```
2025-01-XX 10:15:23 - INFO - üöÄ Configurando entorno para Jetson Nano...
2025-01-XX 10:15:24 - INFO - ‚úÖ CUDA_CACHE_DISABLE=1
2025-01-XX 10:15:25 - INFO - ‚úÖ Swap configurado y activado exitosamente
2025-01-XX 10:15:26 - INFO - ‚úÖ CPU limitada a cores: [0, 1]
2025-01-XX 10:15:27 - INFO - üîç Monitor de recursos iniciado
2025-01-XX 10:15:28 - INFO - üìä Configurando modelo de pose estimation...
2025-01-XX 10:15:30 - INFO - ‚úÖ Modelo configurado exitosamente
2025-01-XX 10:15:31 - INFO - üé¨ Iniciando procesamiento de video...
2025-01-XX 10:15:45 - INFO - üéØ Progreso: 150/3000 (5.0%) - FPS: 10.2 - ETA: 279.4s
2025-01-XX 10:15:55 - INFO - üéØ Progreso: 250/3000 (8.3%) - FPS: 9.8 - ETA: 280.6s
2025-01-XX 10:16:05 - WARNING - ‚ö†Ô∏è  Presi√≥n de memoria: 87.3%, liberando recursos...
```

## Rendimiento Esperado

### Jetson Nano (4GB)
- **FPS**: 8-12 fps (video 1080p)
- **Memoria**: 3-3.5GB uso pico
- **Temperatura**: 45-65¬∞C (con ventilaci√≥n)
- **Tiempo**: ~5-10 min para video de 1 minuto

### Optimizaciones Recomendadas
- Usar modelo MobileNetV2 para mayor velocidad
- Reducir resoluci√≥n de entrada a 720p
- Procesar cada 2do o 3er frame
- Habilitar swap de 4GB para videos largos

---

## Pr√≥ximos Pasos

1. **Ejecutar descargador**: `python download_models_v2.py`
2. **Verificar instalaci√≥n**: Revisar logs de descarga
3. **Probar sistema**: `python example_trt_pose_final.py`
4. **Monitorear recursos**: Observar logs durante ejecuci√≥n
5. **Optimizar configuraci√≥n**: Ajustar seg√∫n rendimiento

## üîß Soluci√≥n al Problema de Swap y Memoria

### üö® **PROBLEMA IDENTIFICADO: ¬øPor qu√© el swap no se usa?**

**RESPUESTA T√âCNICA:**
- El **swap solo funciona para memoria del sistema (RAM)**
- **CUDA/GPU usa memoria unificada** que NO puede extenderse con swap
- Durante `torch2trt`, los **picos de memoria ocurren en GPU**
- Por eso el swap est√° disponible pero **no se usa durante conversi√≥n**

### ‚úÖ **SOLUCI√ìN IMPLEMENTADA: CPU Fallback Autom√°tico**

El convertidor ahora incluye:

```bash
# Conversi√≥n mejorada con fallback autom√°tico
python convert_model_to_tensorrt.py
```

**Flujo autom√°tico:**
1. üîç **Diagn√≥stico inicial** de memoria GPU/CPU/swap
2. üéÆ **Intenta conversi√≥n GPU** primero (5-15 min)
3. üö® **Detecta OOM** autom√°ticamente si ocurre
4. üîÑ **Fallback a CPU** autom√°tico (15-30 min)
5. üíæ **CPU S√ç usa swap** efectivamente
6. ‚úÖ **Verificaci√≥n final** del modelo convertido

### üìä **Diagn√≥stico y Monitoreo**

```bash
# Diagn√≥stico completo del problema de swap
python diagnose_swap_issue.py

# Demostraci√≥n del sistema mejorado
python demo_cpu_fallback.py

# Monitoreo durante conversi√≥n (terminal separado)
watch -n 5 'free -h && swapon --show && nvidia-smi'
```

### üéØ **Ventajas del Sistema Mejorado**

- ‚úÖ **Conversi√≥n siempre exitosa** (GPU o CPU fallback)
- ‚úÖ **Uso efectivo del swap** en modo CPU
- ‚úÖ **Sin intervenci√≥n manual** durante el proceso
- ‚úÖ **Monitoreo detallado** de memoria/swap/temperatura
- ‚úÖ **Diagn√≥stico autom√°tico** de problemas
- ‚úÖ **Reporte final** con estad√≠sticas de rendimiento
