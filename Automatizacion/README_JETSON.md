# TensorRT Pose Estimation - Jetson Nano Optimizado

## DescripciÃ³n

Sistema completo de estimaciÃ³n de poses para Jetson Nano, optimizado para:
- **Monitoreo automÃ¡tico de recursos** (CPU, RAM, GPU, temperatura)
- **Manejo automÃ¡tico de swap** para evitar crashes por memoria
- **LimitaciÃ³n inteligente de CPU** para mantener temperatura controlada
- **Reportes de progreso detallados** con estadÃ­sticas en tiempo real
- **GestiÃ³n robusta de errores** por falta de memoria

## Archivos del Sistema

### Scripts Principales
- `example_trt_pose_final.py` - Script principal optimizado
- `convert_model_to_tensorrt.py` - Convertidor PyTorch â†’ TensorRT con monitoreo completo
- `model_manager.py` - Gestor de modelos con verificaciÃ³n y conversiÃ³n automÃ¡tica
- `download_models_v2.py` - Descargador automÃ¡tico de dependencias
- `utils/jetson_utils.py` - Utilidades especÃ­ficas para Jetson Nano
- `utils/trt_pose_proc.py` - Procesador TensorRT Pose

### Archivos de ConfiguraciÃ³n
- `trt_pose_config.json` - ConfiguraciÃ³n automÃ¡tica generada
- `models/` - Directorio para modelos pre-entrenados
- `configs/` - Directorio para archivos de configuraciÃ³n

## ConversiÃ³n de Modelos PyTorch â†’ TensorRT

### ğŸ”„ ConversiÃ³n AutomÃ¡tica (Recomendado)
```bash
# ConversiÃ³n automÃ¡tica con monitoreo completo
python convert_model_to_tensorrt.py
```

Este proceso:
- âœ… **Configura swap de 4GB** automÃ¡ticamente
- âœ… **Limita CPU a 1 core** para evitar sobrecalentamiento
- âœ… **Monitorea recursos** cada 15 segundos durante conversiÃ³n
- âœ… **Reporta progreso** con temperatura y memoria
- âœ… **Pausas automÃ¡ticas** si temperatura > 70Â°C o memoria > 80%
- âœ… **Verifica modelo convertido** con benchmark de rendimiento
- âœ… **Tiempo estimado**: 5-15 minutos en Jetson Nano

### ğŸ“Š GestiÃ³n de Modelos
```bash
# Verificar estado de modelos
python model_manager.py --check

# ConversiÃ³n solo si es necesario
python model_manager.py --auto

# Validar modelo TensorRT existente
python model_manager.py --validate

# Reporte completo del sistema
python model_manager.py --status
```

### âš™ï¸ ConfiguraciÃ³n Manual de Swap (si falla automÃ¡tico)
```bash
# Crear swap de 4GB para conversiÃ³n
sudo fallocate -l 4G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile

# Verificar swap activo
swapon --show
free -h
```

### ğŸ“ˆ Monitoreo Durante ConversiÃ³n
El script muestra logs como:
```
2025-01-XX 10:15:30 - INFO - âš¡ Iniciando conversiÃ³n PyTorch â†’ TensorRT...
2025-01-XX 10:15:45 - INFO - âœ… Modelo PyTorch: 45.2 MB
2025-01-XX 10:16:00 - INFO - ğŸ”„ Ejecutando torch2trt...
2025-01-XX 10:16:00 - INFO -    Esto puede tomar 5-15 minutos en Jetson Nano...
2025-01-XX 10:16:30 - INFO - â±ï¸ ConversiÃ³n en progreso (0.5 min) - Memoria: 72.3% - Temp: 58.2Â°C
2025-01-XX 10:17:00 - INFO - â±ï¸ ConversiÃ³n en progreso (1.0 min) - Memoria: 75.1% - Temp: 61.4Â°C
2025-01-XX 10:18:00 - WARNING - ğŸŒ¡ï¸ ALERTA TEMPERATURA: 71.2Â°C - Pausando para enfriar...
2025-01-XX 10:20:45 - INFO - âœ… ConversiÃ³n completada en 4.8 minutos
2025-01-XX 10:20:50 - INFO - âœ… Modelo TensorRT guardado: resnet18_baseline_att_224x224_A_epoch_249_trt.pth (38.7 MB)
2025-01-XX 10:21:00 - INFO - ğŸ“Š Resultados de rendimiento:
2025-01-XX 10:21:00 - INFO -    PyTorch: 145.2 ms por inferencia
2025-01-XX 10:21:00 - INFO -    TensorRT: 32.7 ms por inferencia
2025-01-XX 10:21:00 - INFO -    AceleraciÃ³n: 4.4x
```

## InstalaciÃ³n AutomÃ¡tica

### 1. Descargar Dependencias
```bash
# Ejecutar descargador automÃ¡tico
python download_models_v2.py
```

Este script automÃ¡ticamente:
- âœ… Verifica requisitos del sistema
- âœ… Instala dependencias de Python
- âœ… Descarga modelos pre-entrenados
- âœ… Configura directorios necesarios
- âœ… Crea archivo de configuraciÃ³n

### 2. InstalaciÃ³n Manual de TensorRT Pose (si es necesario)
```bash
# Clonar repositorio TensorRT Pose
git clone https://github.com/NVIDIA-AI-IOT/trt_pose
cd trt_pose
sudo python setup.py install

# Clonar torch2trt
git clone https://github.com/NVIDIA-AI-IOT/torch2trt
cd torch2trt
sudo python setup.py install
```

## Uso del Sistema

### ğŸš€ Flujo Completo Recomendado
```bash
# 1. Descargar dependencias
python download_models_v2.py

# 2. Convertir modelo a TensorRT (primera vez)
python convert_model_to_tensorrt.py

# 3. Procesar video con modelo optimizado
python example_trt_pose_final.py
```

### âš¡ ConversiÃ³n RÃ¡pida
```bash
# ConversiÃ³n automÃ¡tica solo si es necesario
python model_manager.py --auto
python example_trt_pose_final.py
```

### ğŸ”§ Uso Avanzado
```bash
# Ejecutar procesamiento con monitoreo automÃ¡tico
python example_trt_pose_final.py
```

### ConfiguraciÃ³n de Swap (automÃ¡tico)
El sistema automÃ¡ticamente:
- Detecta si hay swap activo
- Crea y activa 2GB de swap si es necesario
- Configura permisos apropiados

### Monitoreo Manual de Recursos
```bash
# Monitorear recursos por 5 minutos
python utils/jetson_utils.py 5
```

### ConfiguraciÃ³n Personalizada
Editar `trt_pose_config.json`:
```json
{
  "model_paths": {
    "topology": "configs/human_pose.json",
    "pytorch_model": "models/resnet18_baseline_att_224x224_A_epoch_249.pth",
    "tensorrt_model": "models/resnet18_baseline_att_224x224_A_epoch_249_trt.pth"
  },
  "jetson_config": {
    "enable_swap": true,
    "swap_size_gb": 2,
    "max_cpu_cores": 2,
    "memory_limit_percent": 85,
    "temperature_limit": 75
  }
}
```

## CaracterÃ­sticas del Sistema

### ğŸ” Monitoreo de Recursos
- **CPU**: Uso porcentual y frecuencia
- **Memoria**: RAM y swap con alertas automÃ¡ticas
- **Temperatura**: Monitoreo continuo con alertas
- **GPU**: EstadÃ­sticas usando `tegrastats`
- **Red**: EstadÃ­sticas de trÃ¡fico

### ğŸš¨ Sistema de Alertas
- **Memoria > 85%**: Libera automÃ¡ticamente recursos
- **Temperatura > 75Â°C**: Reduce carga de procesamiento
- **CPU > 90%**: Optimiza uso de cores

### âš™ï¸ Optimizaciones AutomÃ¡ticas
- **Variables de entorno**: ConfiguraciÃ³n CUDA optimizada
- **Afinidad de CPU**: Limita a 2 cores para control tÃ©rmico
- **Cache CUDA**: Deshabilitado para ahorrar memoria
- **Garbage Collection**: AutomÃ¡tico bajo presiÃ³n de memoria

### ğŸ“Š Reportes Detallados
```
=== RECURSOS JETSON (t=145.3s) ===
CPU: 67.2%
RAM: 78.5% (3.1GB/4.0GB)
SWAP: 15.2% (0.3GB/2.0GB)
Temperatura: 52.3Â°C

ğŸ¯ Progreso: 1250/3000 (41.7%) - FPS: 8.6 - ETA: 203.4s
```

## Flujo de Procesamiento

### 1. InicializaciÃ³n
- âœ… Configurar swap automÃ¡tico
- âœ… Limitar cores de CPU
- âœ… Iniciar monitoreo de recursos
- âœ… Cargar modelo TensorRT optimizado

### 2. Procesamiento de Video
- ğŸ¬ Abrir video de entrada
- ğŸ”„ Procesar frame por frame con keypoints
- ğŸ¨ Dibujar esqueleto en tiempo real
- ğŸ’¾ Guardar video procesado
- ğŸ“ˆ Reportar progreso cada 10 segundos

### 3. Manejo de Recursos
- ğŸš¨ Detectar presiÃ³n de memoria
- ğŸ§¹ Liberar recursos automÃ¡ticamente
- ğŸŒ¡ï¸ Monitorear temperatura
- â¸ï¸ Pausas automÃ¡ticas para enfriamiento

### 4. FinalizaciÃ³n
- ğŸ“Š EstadÃ­sticas completas
- ğŸ§¹ Limpieza de recursos
- ğŸ”„ Restaurar configuraciÃ³n CPU

## Comandos de Monitoreo Manual

### Verificar Estado del Sistema
```bash
# Temperatura
cat /sys/devices/virtual/thermal/thermal_zone0/temp

# Memoria
free -h

# Swap
swapon --show

# GPU (si tegrastats estÃ¡ disponible)
tegrastats --interval 1000
```

### Configurar Swap Manualmente
```bash
# Crear swap de 2GB
sudo fallocate -l 2G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile

# Verificar
swapon --show
```

### Limitar CPU Manualmente
```bash
# Limitar proceso a cores 0 y 1
taskset -cp 0,1 [PID]

# Verificar afinidad
taskset -p [PID]
```

## SoluciÃ³n de Problemas

### Error: "Out of Memory"
```bash
# Verificar memoria disponible
free -h

# Activar swap si no estÃ¡ activo
sudo swapon /swapfile

# Reducir resoluciÃ³n de video o procesar menos frames
```

### Error: "Model not found"
```bash
# Ejecutar descargador automÃ¡tico
python download_models_v2.py

# Verificar rutas en configuraciÃ³n
cat trt_pose_config.json
```

### Temperatura alta (>80Â°C)
```bash
# El sistema automÃ¡ticamente:
# - Pausa procesamiento
# - Reduce cores de CPU
# - Limpia memoria

# Verificar ventilaciÃ³n del Jetson Nano
```

### Rendimiento bajo
```bash
# Verificar uso de TensorRT
# Ver logs del script para confirmar modelo optimizado

# Reducir resoluciÃ³n de entrada
# Procesar menos frames por segundo
```

## Logs y DepuraciÃ³n

### Habilitar Logs Detallados
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### Archivos de Log
- Salida estÃ¡ndar: Progreso y estadÃ­sticas
- Alertas: Eventos de recursos y temperaturas
- Errores: Problemas de procesamiento

### Ejemplo de Log Completo
```
2025-01-XX 10:15:23 - INFO - ğŸš€ Configurando entorno para Jetson Nano...
2025-01-XX 10:15:24 - INFO - âœ… CUDA_CACHE_DISABLE=1
2025-01-XX 10:15:25 - INFO - âœ… Swap configurado y activado exitosamente
2025-01-XX 10:15:26 - INFO - âœ… CPU limitada a cores: [0, 1]
2025-01-XX 10:15:27 - INFO - ğŸ” Monitor de recursos iniciado
2025-01-XX 10:15:28 - INFO - ğŸ“Š Configurando modelo de pose estimation...
2025-01-XX 10:15:30 - INFO - âœ… Modelo configurado exitosamente
2025-01-XX 10:15:31 - INFO - ğŸ¬ Iniciando procesamiento de video...
2025-01-XX 10:15:45 - INFO - ğŸ¯ Progreso: 150/3000 (5.0%) - FPS: 10.2 - ETA: 279.4s
2025-01-XX 10:15:55 - INFO - ğŸ¯ Progreso: 250/3000 (8.3%) - FPS: 9.8 - ETA: 280.6s
2025-01-XX 10:16:05 - WARNING - âš ï¸  PresiÃ³n de memoria: 87.3%, liberando recursos...
```

## Rendimiento Esperado

### Jetson Nano (4GB)
- **FPS**: 8-12 fps (video 1080p)
- **Memoria**: 3-3.5GB uso pico
- **Temperatura**: 45-65Â°C (con ventilaciÃ³n)
- **Tiempo**: ~5-10 min para video de 1 minuto

### Optimizaciones Recomendadas
- Usar modelo MobileNetV2 para mayor velocidad
- Reducir resoluciÃ³n de entrada a 720p
- Procesar cada 2do o 3er frame
- Habilitar swap de 4GB para videos largos

---

## PrÃ³ximos Pasos

1. **Ejecutar descargador**: `python download_models_v2.py`
2. **Verificar instalaciÃ³n**: Revisar logs de descarga
3. **Probar sistema**: `python example_trt_pose_final.py`
4. **Monitorear recursos**: Observar logs durante ejecuciÃ³n
5. **Optimizar configuraciÃ³n**: Ajustar segÃºn rendimiento

## ğŸ”§ SoluciÃ³n al Problema de Swap y Memoria

### ğŸš¨ **PROBLEMA IDENTIFICADO: Â¿Por quÃ© el swap no se usa?**

**RESPUESTA TÃ‰CNICA:**
- El **swap solo funciona para memoria del sistema (RAM)**
- **CUDA/GPU usa memoria unificada** que NO puede extenderse con swap
- Durante `torch2trt`, los **picos de memoria ocurren en GPU**
- Por eso el swap estÃ¡ disponible pero **no se usa durante conversiÃ³n**

### âœ… **SOLUCIÃ“N IMPLEMENTADA: CPU Fallback AutomÃ¡tico**

El convertidor ahora incluye:

```bash
# ConversiÃ³n mejorada con fallback automÃ¡tico
python convert_model_to_tensorrt.py
```

**Flujo automÃ¡tico:**
1. ğŸ” **DiagnÃ³stico inicial** de memoria GPU/CPU/swap
2. ğŸ® **Intenta conversiÃ³n GPU** primero (5-15 min)
3. ğŸš¨ **Detecta OOM** automÃ¡ticamente si ocurre
4. ğŸ”„ **Fallback a CPU** automÃ¡tico (15-30 min)
5. ğŸ’¾ **CPU SÃ usa swap** efectivamente
6. âœ… **VerificaciÃ³n final** del modelo convertido

### ğŸ“Š **DiagnÃ³stico y Monitoreo**

```bash
# DiagnÃ³stico completo del problema de swap
python diagnose_swap_issue.py

# DemostraciÃ³n del sistema mejorado
python demo_cpu_fallback.py

# Monitoreo durante conversiÃ³n (terminal separado)
watch -n 5 'free -h && swapon --show && nvidia-smi'
```

### ğŸ¯ **Ventajas del Sistema Mejorado**

- âœ… **ConversiÃ³n siempre exitosa** (GPU o CPU fallback)
- âœ… **Uso efectivo del swap** en modo CPU
- âœ… **Sin intervenciÃ³n manual** durante el proceso
- âœ… **Monitoreo detallado** de memoria/swap/temperatura
- âœ… **DiagnÃ³stico automÃ¡tico** de problemas
- âœ… **Reporte final** con estadÃ­sticas de rendimiento
