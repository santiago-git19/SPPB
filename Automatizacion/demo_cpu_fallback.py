#!/usr/bin/env python3
"""
DemostraciÃ³n: ConversiÃ³n TensorRT con CPU Fallback
=================================================

Script que demuestra la conversiÃ³n mejorada con fallback automÃ¡tico a CPU
cuando la conversiÃ³n GPU falla por falta de memoria.

Uso:
    python demo_cpu_fallback.py
    
CaracterÃ­sticas:
- Detecta automÃ¡ticamente si GPU tiene suficiente memoria
- Fallback a CPU que SÃ usa swap efectivamente
- Monitoreo detallado durante ambos tipos de conversiÃ³n
- Reporte final de rendimiento

Autor: Sistema de IA  
Fecha: 2025
"""

import json
import os
import sys
import time
import logging
from pathlib import Path

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def demo_conversion_strategies():
    """Demuestra las diferentes estrategias de conversiÃ³n"""
    
    logger.info("ğŸš€ DEMOSTRACIÃ“N: Estrategias de ConversiÃ³n TensorRT")
    logger.info("="*60)
    
    # Verificar si el convertidor mejorado existe
    converter_path = Path("convert_model_to_tensorrt.py")
    if not converter_path.exists():
        logger.error("âŒ No se encontrÃ³ convert_model_to_tensorrt.py")
        return False
    
    logger.info("ğŸ“‹ ESTRATEGIAS DISPONIBLES:")
    logger.info("1. ğŸ® ConversiÃ³n GPU (rÃ¡pida, puede fallar por OOM)")
    logger.info("2. ğŸ§  ConversiÃ³n CPU con swap (lenta pero estable)")  
    logger.info("3. ğŸ”„ Fallback automÃ¡tico (intenta GPU â†’ CPU si falla)")
    
    # Mostrar configuraciÃ³n actual
    show_current_configuration()
    
    # Ejecutar diagnÃ³stico previo
    run_pre_conversion_diagnostic()
    
    # Simular conversiÃ³n con monitoreo
    simulate_conversion_process()
    
    return True

def show_current_configuration():
    """Muestra configuraciÃ³n actual del sistema"""
    logger.info("\nğŸ”§ CONFIGURACIÃ“N ACTUAL:")
    
    try:
        import psutil
        
        # Memoria
        mem = psutil.virtual_memory()
        swap = psutil.swap_memory()
        
        logger.info(f"   RAM Total: {mem.total/(1024**3):.1f} GB")
        logger.info(f"   RAM Disponible: {mem.available/(1024**3):.1f} GB")
        
        if swap.total > 0:
            logger.info(f"   âœ… Swap: {swap.total/(1024**3):.1f} GB configurado")
        else:
            logger.warning("   âš ï¸ Sin swap configurado")
            
        # CUDA si disponible
        try:
            import torch
            if torch.cuda.is_available():
                total_cuda = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                logger.info(f"   ğŸ® CUDA: {total_cuda:.1f} GB ({torch.cuda.get_device_name(0)})")
            else:
                logger.warning("   âš ï¸ CUDA no disponible")
        except ImportError:
            logger.warning("   âš ï¸ PyTorch no instalado")
            
    except ImportError:
        logger.warning("   âš ï¸ psutil no disponible para mostrar configuraciÃ³n")

def run_pre_conversion_diagnostic():
    """Ejecuta diagnÃ³stico previo a la conversiÃ³n"""
    logger.info("\nğŸ” DIAGNÃ“STICO PRE-CONVERSIÃ“N:")
    
    # Verificar archivos necesarios
    required_files = [
        '/home/mobilenet/Documentos/Trabajo/trt_pose/models/resnet18_baseline_att_224x224_A_epoch_249.pth',
        '/home/mobilenet/Documentos/Trabajo/trt_pose/tasks/human_pose/human_pose.json'
    ]
    
    all_files_exist = True
    for file_path in required_files:
        if os.path.exists(file_path):
            logger.info(f"   âœ… {os.path.basename(file_path)}")
        else:
            logger.warning(f"   âš ï¸ No encontrado: {os.path.basename(file_path)}")
            all_files_exist = False
    
    if not all_files_exist:
        logger.warning("   ğŸ’¡ Algunos archivos no estÃ¡n disponibles (esto es normal en demo)")
    
    # Predecir estrategia recomendada
    predict_recommended_strategy()

def predict_recommended_strategy():
    """Predice quÃ© estrategia de conversiÃ³n serÃ­a recomendada"""
    logger.info("\nğŸ¯ PREDICCIÃ“N DE ESTRATEGIA:")
    
    try:
        import psutil
        
        mem = psutil.virtual_memory()
        available_gb = mem.available / (1024**3)
        
        try:
            import torch
            if torch.cuda.is_available():
                cuda_available = True
                cuda_free = (torch.cuda.get_device_properties(0).total_memory - 
                            torch.cuda.memory_reserved(0)) / (1024**3)
            else:
                cuda_available = False
                cuda_free = 0
        except ImportError:
            cuda_available = False
            cuda_free = 0
        
        logger.info(f"   RAM disponible: {available_gb:.1f} GB")
        if cuda_available:
            logger.info(f"   CUDA libre: {cuda_free:.1f} GB")
        
        # LÃ³gica de predicciÃ³n
        if cuda_available and cuda_free > 1.0:
            logger.info("   ğŸ’¡ RECOMENDACIÃ“N: Intentar GPU primero")
            logger.info("   ğŸ“Š Probabilidad de Ã©xito GPU: Alta")
        elif cuda_available and cuda_free > 0.5:
            logger.info("   ğŸ’¡ RECOMENDACIÃ“N: GPU con fallback CPU")
            logger.info("   ğŸ“Š Probabilidad de Ã©xito GPU: Media")
        else:
            logger.info("   ğŸ’¡ RECOMENDACIÃ“N: ConversiÃ³n CPU directa")
            logger.info("   ğŸ“Š Probabilidad de Ã©xito GPU: Baja")
        
        if available_gb > 2.0:
            logger.info("   ğŸ“Š Probabilidad de Ã©xito CPU: Alta")
        else:
            logger.warning("   ğŸ“Š Probabilidad de Ã©xito CPU: Media (necesita swap)")
            
    except ImportError:
        logger.warning("   âš ï¸ No se puede predecir estrategia sin psutil")

def simulate_conversion_process():
    """Simula el proceso de conversiÃ³n mejorado"""
    logger.info("\nğŸ”„ SIMULACIÃ“N DE CONVERSIÃ“N:")
    
    logger.info("   ğŸ“ Pasos del proceso mejorado:")
    logger.info("   1. ğŸ” DiagnÃ³stico inicial de memoria")
    logger.info("   2. ğŸ® Intento de conversiÃ³n GPU")
    logger.info("   3. ğŸš¨ DetecciÃ³n de OOM (si ocurre)")
    logger.info("   4. ğŸ”„ Fallback automÃ¡tico a CPU")
    logger.info("   5. ğŸ’¾ ConversiÃ³n CPU usando swap")
    logger.info("   6. âœ… VerificaciÃ³n del modelo final")
    
    # Simular flujo de decisiÃ³n
    logger.info("\n   ğŸ¤– FLUJO DE DECISIÃ“N AUTOMÃTICO:")
    
    # Paso 1: DiagnÃ³stico
    logger.info("   [1/6] ğŸ” Ejecutando diagnÃ³stico...")
    time.sleep(1)
    logger.info("         âœ… Memoria analizada")
    logger.info("         âœ… CUDA verificado")
    logger.info("         âœ… Swap confirmado")
    
    # Paso 2: Intento GPU
    logger.info("   [2/6] ğŸ® Iniciando conversiÃ³n GPU...")
    time.sleep(1.5)
    
    # Simular decisiÃ³n basada en memoria disponible
    try:
        import psutil
        available_gb = psutil.virtual_memory().available / (1024**3)
        
        if available_gb < 1.5:  # Simular condiciÃ³n de poca memoria
            logger.warning("         âš ï¸ Memoria insuficiente detectada")
            logger.warning("         ğŸš¨ OOM simulado despuÃ©s de 2 minutos")
            
            # Paso 3: DetecciÃ³n OOM
            logger.info("   [3/6] ğŸš¨ Detectando OOM...")
            time.sleep(1)
            logger.warning("         âŒ torch.cuda.OutOfMemoryError capturado")
            
            # Paso 4: Fallback
            logger.info("   [4/6] ğŸ”„ Activando fallback CPU...")
            time.sleep(1)
            logger.info("         âœ… Modelo movido a CPU")
            logger.info("         âœ… Memoria GPU liberada")
            
            # Paso 5: ConversiÃ³n CPU
            logger.info("   [5/6] ğŸ’¾ ConversiÃ³n CPU con swap...")
            time.sleep(2)
            logger.info("         âœ… Swap siendo usado efectivamente")
            logger.info("         â° Progreso: conversiÃ³n mÃ¡s lenta pero estable")
            
        else:
            logger.info("         âœ… ConversiÃ³n GPU completada exitosamente")
            logger.info("         â±ï¸ Tiempo: ~8 minutos")
        
        # Paso 6: VerificaciÃ³n
        logger.info("   [6/6] âœ… Verificando modelo final...")
        time.sleep(1)
        logger.info("         âœ… Modelo TensorRT validado")
        logger.info("         âœ… Benchmark de rendimiento ejecutado")
        
    except ImportError:
        logger.info("         âœ… ConversiÃ³n GPU (simulada)")
    
    # Resumen final
    show_conversion_summary()

def show_conversion_summary():
    """Muestra resumen de la conversiÃ³n"""
    logger.info("\nğŸ“Š RESUMEN DE CONVERSIÃ“N:")
    
    logger.info("   ğŸ¯ BENEFICIOS DE LA MEJORA:")
    logger.info("   âœ… DetecciÃ³n automÃ¡tica de limitaciones de memoria")
    logger.info("   âœ… Fallback transparente sin intervenciÃ³n manual")
    logger.info("   âœ… Uso efectivo del swap en modo CPU")
    logger.info("   âœ… Monitoreo detallado durante todo el proceso")
    logger.info("   âœ… Mayor robustez contra OOM errors")
    
    logger.info("\n   ğŸ“ˆ IMPACTO EN RENDIMIENTO:")
    logger.info("   ğŸ® GPU: 5-15 min (si hay suficiente memoria)")
    logger.info("   ğŸ§  CPU: 15-30 min (siempre funciona con swap)")
    logger.info("   ğŸ”„ Fallback: Combina lo mejor de ambos mundos")
    
    logger.info("\n   ğŸ”§ CONFIGURACIÃ“N RECOMENDADA:")
    logger.info("   ğŸ’¾ Swap: 4GB mÃ­nimo para conversiÃ³n")
    logger.info("   ğŸŒ¡ï¸ Temperatura: <70Â°C durante conversiÃ³n")
    logger.info("   ğŸ’» CPU: MÃ¡ximo 2 cores para evitar sobrecalentamiento")
    logger.info("   ğŸ“± Aplicaciones: Cerrar aplicaciones innecesarias")

def show_usage_examples():
    """Muestra ejemplos de uso"""
    logger.info("\nğŸ“š EJEMPLOS DE USO:")
    
    logger.info("   ğŸ”„ ConversiÃ³n automÃ¡tica (recomendado):")
    logger.info("     python convert_model_to_tensorrt.py")
    logger.info("     # Usa fallback automÃ¡tico si es necesario")
    
    logger.info("\n   ğŸ§  Forzar conversiÃ³n CPU:")
    logger.info("     python convert_model_to_tensorrt.py --force-cpu")
    logger.info("     # Usa CPU directamente (mÃ¡s lento pero estable)")
    
    logger.info("\n   ğŸ” Solo diagnÃ³stico:")
    logger.info("     python diagnose_swap_issue.py")
    logger.info("     # Analiza configuraciÃ³n sin convertir")
    
    logger.info("\n   ğŸ“Š Monitor de recursos:")
    logger.info("     # En terminal separado durante conversiÃ³n:")
    logger.info("     watch -n 5 'free -h && swapon --show'")

def main():
    """FunciÃ³n principal"""
    logger.info("ğŸ­ Iniciando demostraciÃ³n de conversiÃ³n mejorada...")
    
    try:
        # Ejecutar demostraciÃ³n
        success = demo_conversion_strategies()
        
        if success:
            # Mostrar ejemplos de uso
            show_usage_examples()
            
            logger.info("\n" + "="*60)
            logger.info("âœ… DEMOSTRACIÃ“N COMPLETADA")
            logger.info("ğŸ’¡ El sistema ahora incluye:")
            logger.info("   ğŸ”„ Fallback automÃ¡tico CPU cuando GPU falla")
            logger.info("   ğŸ“Š DiagnÃ³stico detallado de memoria")
            logger.info("   ğŸ’¾ Uso efectivo del swap en modo CPU")
            logger.info("   ğŸ” Monitoreo durante toda la conversiÃ³n")
            logger.info("\nğŸ“‹ Para ejecutar conversiÃ³n real:")
            logger.info("   python convert_model_to_tensorrt.py")
            
            return 0
        else:
            logger.error("âŒ Error durante demostraciÃ³n")
            return 1
            
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸ DemostraciÃ³n interrumpida por usuario")
        return 1
    except Exception as e:
        logger.error(f"âŒ Error durante demostraciÃ³n: {e}")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
