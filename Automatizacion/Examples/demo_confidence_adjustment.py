#!/usr/bin/env python3
"""
Prueba del Ajuste de Confianza en process_keypoints
==================================================

Script para probar la nueva funcionalidad de ajuste de confianza
integrada en el m√©todo process_keypoints de TRTPoseClassifier.

Autor: Sistema de IA
Fecha: 2025
"""

import numpy as np
import sys
from pathlib import Path

# A√±adir ruta del m√≥dulo
sys.path.append(str(Path(__file__).resolve().parent.parent))

def demo_confidence_adjustment():
    """
    Demostraci√≥n de c√≥mo funciona el ajuste de confianza en process_keypoints
    """
    print("üéØ Demostraci√≥n: Ajuste de Confianza en process_keypoints")
    print("=" * 60)
    
    # Crear keypoints de ejemplo con diferentes niveles de confianza
    test_keypoints = [
        # Caso 1: Keypoints con confianzas variadas
        np.array([
            [100, 200, 0.15],  # Muy baja confianza - ser√° descartado
            [150, 180, 0.25],  # Baja confianza - ser√° descartado
            [200, 160, 0.35],  # Confianza baja-media - ser√° ajustado
            [250, 140, 0.5],   # Confianza media - ser√° ajustado
            [300, 120, 0.7],   # Confianza alta - ser√° ajustado
            [350, 100, 0.9],   # Muy alta confianza - ser√° ajustado ligeramente
            [400, 80, 0.4],    # Confianza media-baja - ser√° ajustado
            [450, 60, 0.6],    # Confianza media-alta - ser√° ajustado
            [500, 40, 0.8],    # Confianza alta - ser√° ajustado
            [0, 0, 0.0],       # Keypoint inv√°lido - ser√° descartado
        ]),
        
        # Caso 2: Todos los keypoints v√°lidos
        np.array([
            [50, 100, 0.4],
            [100, 150, 0.6],
            [150, 200, 0.8],
            [200, 250, 0.95],
            [250, 300, 0.5],
        ]),
        
        # Caso 3: Mezcla con algunos inv√°lidos
        np.array([
            [75, 125, 0.2],    # Ser√° descartado
            [125, 175, 0.45],  # Ser√° ajustado
            [175, 225, 0.1],   # Ser√° descartado
            [225, 275, 0.85],  # Ser√° ajustado
            [275, 325, 0.3],   # En el l√≠mite - ser√° ajustado
        ])
    ]
    
    # Simular el comportamiento del clasificador sin crear instancia completa
    confidence_threshold = 0.3
    
    for i, keypoints in enumerate(test_keypoints, 1):
        print(f"\nüìã Caso {i}: Keypoints de prueba")
        print("-" * 40)
        
        print(f"üìä Keypoints originales ({len(keypoints)}):")
        for j, kp in enumerate(keypoints):
            status = "‚ùå Descartado" if kp[2] < confidence_threshold else "‚úÖ V√°lido"
            print(f"   [{j:2d}] x={kp[0]:3.0f}, y={kp[1]:3.0f}, conf={kp[2]:.2f} - {status}")
        
        # Simular el procesamiento completo que hace _adjust_keypoint_confidence
        result = simulate_full_processing(keypoints, confidence_threshold)
        
        print(f"\nüìà Resultado despu√©s del ajuste:")
        print(f"   üîß Keypoints procesados: {len(result)} (formato convertido)")
        
        for j, kp in enumerate(result):
            if kp[2] > 0:  # Solo mostrar keypoints no descartados
                print(f"   [{j:2d}] x={kp[0]:6.3f}, y={kp[1]:6.3f}, conf={kp[2]:.3f}")
            else:
                print(f"   [{j:2d}] x={kp[0]:6.3f}, y={kp[1]:6.3f}, conf={kp[2]:.3f} (descartado)")
        
        # Estad√≠sticas del caso
        original_valid = np.sum(keypoints[:, 2] >= confidence_threshold)
        processed_valid = np.sum(result[:, 2] > 0)
        
        print(f"\nüìä Estad√≠sticas del caso {i}:")
        print(f"   üì• Keypoints originales: {len(keypoints)}")
        print(f"   ‚úÖ V√°lidos originalmente: {original_valid}")
        print(f"   üì§ Keypoints procesados: {len(result)}")
        print(f"   üéØ V√°lidos tras procesamiento: {processed_valid}")
        
        if original_valid > 0:
            original_range = keypoints[keypoints[:, 2] >= confidence_threshold, 2]
            processed_range = result[result[:, 2] > 0, 2]
            if len(processed_range) > 0:
                print(f"   üìà Confianza original: [{np.min(original_range):.3f}, {np.max(original_range):.3f}]")
                print(f"   üìà Confianza ajustada: [{np.min(processed_range):.3f}, {np.max(processed_range):.3f}]")

def simulate_full_processing(keypoints: np.ndarray, 
                           threshold: float,
                           boost_factor: float = 2.0,
                           max_confidence: float = 0.95) -> np.ndarray:
    """
    Simula el procesamiento completo que hace _adjust_keypoint_confidence
    """
    # Paso 1: Filtrar keypoints con baja confianza
    filtered = keypoints.copy()
    low_confidence_mask = keypoints[:, 2] < threshold
    filtered[low_confidence_mask] = [0.0, 0.0, 0.0]
    
    # Paso 2: Ajustar confianza de keypoints v√°lidos
    adjusted = filtered.copy()
    valid_mask = (filtered[:, 2] >= threshold)
    
    if np.any(valid_mask):
        valid_confidences = filtered[valid_mask, 2]
        
        # F√≥rmula de ajuste suave usando funci√≥n sigmoide
        normalized_conf = (valid_confidences - threshold) / (1.0 - threshold)
        sigmoid_steepness = 3.0
        sigmoid_scale = 1.0 / (1.0 + np.exp(-sigmoid_steepness * (normalized_conf - 0.5)))
        
        confidence_increment = (normalized_conf * boost_factor * sigmoid_scale)
        new_confidences = threshold + confidence_increment * (1.0 - threshold)
        new_confidences = np.minimum(new_confidences, max_confidence)
        
        adjusted[valid_mask, 2] = new_confidences
    
    # Paso 3: Simulaci√≥n de conversi√≥n de formato (mantener como est√° para demo)
    converted = adjusted
    
    # Paso 4: Simulaci√≥n de normalizaci√≥n b√°sica
    normalized = converted.copy()
    valid_mask = (converted[:, 0] != 0) | (converted[:, 1] != 0)
    
    if np.any(valid_mask):
        valid_keypoints = converted[valid_mask]
        if len(valid_keypoints) > 0:
            x_coords = valid_keypoints[:, 0]
            y_coords = valid_keypoints[:, 1]
            
            # Normalizaci√≥n b√°sica
            if np.max(x_coords) > np.min(x_coords):
                x_center = np.mean(x_coords)
                x_scale = np.max(x_coords) - np.min(x_coords)
                normalized[valid_mask, 0] = (x_coords - x_center) / x_scale
            
            if np.max(y_coords) > np.min(y_coords):
                y_center = np.mean(y_coords)
                y_scale = np.max(y_coords) - np.min(y_coords)
                normalized[valid_mask, 1] = (y_coords - y_center) / y_scale
    
    return normalized

def show_formula_explanation():
    """
    Explica la f√≥rmula de ajuste de confianza utilizada
    """
    print("\nüî¨ Explicaci√≥n de la F√≥rmula de Ajuste")
    print("=" * 50)
    
    print("üìê F√≥rmula utilizada:")
    print("   1. normalized_conf = (original_conf - threshold) / (1.0 - threshold)")
    print("   2. sigmoid_scale = 1 / (1 + exp(-3.0 * (normalized_conf - 0.5)))")
    print("   3. increment = normalized_conf * boost_factor * sigmoid_scale")
    print("   4. new_conf = threshold + increment * (1.0 - threshold)")
    print("   5. final_conf = min(new_conf, max_confidence)")
    
    print("\nüéØ Par√°metros:")
    print("   ‚Ä¢ threshold: 0.3 (m√≠nimo para ser v√°lido)")
    print("   ‚Ä¢ boost_factor: 2.0 (multiplicador de incremento)")
    print("   ‚Ä¢ max_confidence: 0.95 (l√≠mite superior)")
    print("   ‚Ä¢ sigmoid_steepness: 3.0 (suavidad de la transici√≥n)")
    
    print("\nüí° Caracter√≠sticas:")
    print("   ‚úÖ Incremento proporcional (no lineal)")
    print("   ‚úÖ Transici√≥n suave (funci√≥n sigmoide)")
    print("   ‚úÖ L√≠mite m√°ximo para evitar sobreajuste")
    print("   ‚úÖ Reutiliza funciones existentes del clasificador")

if __name__ == "__main__":
    # Ejecutar demostraci√≥n
    demo_confidence_adjustment()
    show_formula_explanation()
    
    print(f"\n‚úÖ Demostraci√≥n completada")
    print(f"üí° La funcionalidad est√° integrada en process_keypoints()")
    print(f"üîß Reutiliza las funciones existentes:")
    print(f"   - _filter_low_confidence_keypoints()")
    print(f"   - _convert_keypoints_format()")
    print(f"   - _normalize_keypoints()")
